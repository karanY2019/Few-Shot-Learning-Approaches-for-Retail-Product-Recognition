{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test1', 'train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\april\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "import os\n",
    "import datetime\n",
    "print(os.listdir(\"Birds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Full training set: CUB dataset 40 classes+Grocery dataset 20 classes.\n",
    "\n",
    "#Full test set: CUB 14 classes+Grocery 11 classes\n",
    "#Train and test sets are totally disjoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.listdir('Birds/train/') \n",
    "datax = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUB-Birds: Train clsses[1-40], test class[170-183], NO AUGMENTATION, STACK ONLY 1 TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "charct = os.listdir('Birds/train/')\n",
    "alphabet_directory_train='Birds/train/'\n",
    "trdatay = []\n",
    "trdatax=[]\n",
    "for character in charct:\n",
    "        images = os.listdir('Birds/train/' + character + '/')\n",
    "        for img in images:\n",
    "            image = cv2.resize(cv2.imread(alphabet_directory_train + character + '/' + img), (42,42))\n",
    "            #image = np.expand_dims(image, 0)\n",
    "            trdatax.append( image)\n",
    "            trdatay.append(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2290, 42, 42, 3), (2290,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx=np.array(trdatax)\n",
    "trainy=np.array(trdatay)\n",
    "trainx.shape, trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[176, 177, 173],\n",
       "         [171, 172, 168],\n",
       "         [160, 160, 154],\n",
       "         ...,\n",
       "         [184, 184, 178],\n",
       "         [179, 181, 175],\n",
       "         [184, 186, 180]],\n",
       "\n",
       "        [[157, 158, 154],\n",
       "         [160, 161, 157],\n",
       "         [166, 167, 162],\n",
       "         ...,\n",
       "         [183, 183, 177],\n",
       "         [185, 187, 182],\n",
       "         [188, 190, 184]],\n",
       "\n",
       "        [[174, 175, 171],\n",
       "         [182, 183, 179],\n",
       "         [180, 181, 178],\n",
       "         ...,\n",
       "         [187, 187, 181],\n",
       "         [177, 179, 173],\n",
       "         [167, 169, 163]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[162, 163, 159],\n",
       "         [122, 125, 116],\n",
       "         [126, 130, 120],\n",
       "         ...,\n",
       "         [162, 163, 158],\n",
       "         [161, 166, 157],\n",
       "         [150, 155, 147]],\n",
       "\n",
       "        [[163, 164, 159],\n",
       "         [163, 165, 159],\n",
       "         [167, 170, 163],\n",
       "         ...,\n",
       "         [161, 163, 157],\n",
       "         [175, 178, 176],\n",
       "         [171, 174, 172]],\n",
       "\n",
       "        [[162, 163, 158],\n",
       "         [167, 169, 166],\n",
       "         [178, 179, 177],\n",
       "         ...,\n",
       "         [160, 162, 156],\n",
       "         [161, 166, 160],\n",
       "         [170, 173, 168]]],\n",
       "\n",
       "\n",
       "       [[[169, 142, 125],\n",
       "         [175, 147, 127],\n",
       "         [203, 193, 178],\n",
       "         ...,\n",
       "         [169, 138, 108],\n",
       "         [141, 120,  82],\n",
       "         [131, 107,  70]],\n",
       "\n",
       "        [[115,  88,  47],\n",
       "         [161, 128, 107],\n",
       "         [166, 162, 146],\n",
       "         ...,\n",
       "         [205, 187, 159],\n",
       "         [180, 146, 117],\n",
       "         [179, 139, 114]],\n",
       "\n",
       "        [[ 81,  64,  26],\n",
       "         [ 93,  70,  31],\n",
       "         [140, 106,  77],\n",
       "         ...,\n",
       "         [158, 119,  93],\n",
       "         [190, 152, 126],\n",
       "         [178, 140, 113]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  2,   1,   3],\n",
       "         [178, 175, 164],\n",
       "         [175, 164, 154],\n",
       "         ...,\n",
       "         [215, 212, 207],\n",
       "         [218, 188, 144],\n",
       "         [191, 182, 174]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 98,  88,  64],\n",
       "         [142, 130, 100],\n",
       "         ...,\n",
       "         [232, 226, 217],\n",
       "         [222, 207, 197],\n",
       "         [189, 193, 206]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  2,   2,   1],\n",
       "         [174, 163, 143],\n",
       "         ...,\n",
       "         [224, 195, 146],\n",
       "         [203, 176, 136],\n",
       "         [223, 214, 197]]],\n",
       "\n",
       "\n",
       "       [[[205, 206, 206],\n",
       "         [221, 219, 219],\n",
       "         [218, 216, 216],\n",
       "         ...,\n",
       "         [121, 127, 116],\n",
       "         [138, 147, 143],\n",
       "         [174, 181, 183]],\n",
       "\n",
       "        [[223, 221, 221],\n",
       "         [242, 239, 236],\n",
       "         [231, 231, 233],\n",
       "         ...,\n",
       "         [200, 201, 202],\n",
       "         [206, 208, 209],\n",
       "         [202, 204, 205]],\n",
       "\n",
       "        [[240, 238, 238],\n",
       "         [230, 225, 226],\n",
       "         [231, 226, 227],\n",
       "         ...,\n",
       "         [169, 175, 173],\n",
       "         [169, 178, 179],\n",
       "         [168, 177, 180]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[204, 210, 209],\n",
       "         [183, 191, 190],\n",
       "         [194, 201, 200],\n",
       "         ...,\n",
       "         [193, 201, 200],\n",
       "         [192, 196, 197],\n",
       "         [207, 211, 211]],\n",
       "\n",
       "        [[201, 202, 206],\n",
       "         [215, 214, 216],\n",
       "         [215, 214, 216],\n",
       "         ...,\n",
       "         [198, 200, 200],\n",
       "         [194, 199, 202],\n",
       "         [187, 192, 195]],\n",
       "\n",
       "        [[195, 198, 198],\n",
       "         [202, 196, 201],\n",
       "         [221, 221, 223],\n",
       "         ...,\n",
       "         [180, 184, 185],\n",
       "         [201, 207, 206],\n",
       "         [187, 194, 192]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[112, 123, 121],\n",
       "         [113, 126, 118],\n",
       "         [114, 125, 115],\n",
       "         ...,\n",
       "         [111, 124, 126],\n",
       "         [121, 127, 126],\n",
       "         [133, 130, 126]],\n",
       "\n",
       "        [[117, 127, 121],\n",
       "         [118, 129, 119],\n",
       "         [117, 128, 118],\n",
       "         ...,\n",
       "         [116, 127, 130],\n",
       "         [128, 131, 131],\n",
       "         [142, 135, 132]],\n",
       "\n",
       "        [[120, 131, 123],\n",
       "         [119, 131, 119],\n",
       "         [118, 129, 119],\n",
       "         ...,\n",
       "         [121, 132, 136],\n",
       "         [133, 136, 137],\n",
       "         [148, 141, 138]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 41,  95, 106],\n",
       "         [ 39,  97, 109],\n",
       "         [ 38,  96, 108],\n",
       "         ...,\n",
       "         [103, 131, 131],\n",
       "         [106, 132, 132],\n",
       "         [108, 134, 134]],\n",
       "\n",
       "        [[ 42,  94, 107],\n",
       "         [ 41,  94, 107],\n",
       "         [ 37,  94, 109],\n",
       "         ...,\n",
       "         [ 85, 123, 126],\n",
       "         [ 92, 127, 131],\n",
       "         [ 92, 127, 130]],\n",
       "\n",
       "        [[ 41,  90, 104],\n",
       "         [ 40,  92, 105],\n",
       "         [ 41,  93, 106],\n",
       "         ...,\n",
       "         [ 71, 116, 120],\n",
       "         [ 75, 117, 122],\n",
       "         [ 77, 119, 124]]],\n",
       "\n",
       "\n",
       "       [[[116, 160, 190],\n",
       "         [111, 158, 184],\n",
       "         [113, 160, 179],\n",
       "         ...,\n",
       "         [121, 157, 183],\n",
       "         [113, 158, 181],\n",
       "         [118, 162, 187]],\n",
       "\n",
       "        [[119, 161, 189],\n",
       "         [ 43, 103,  75],\n",
       "         [ 36, 100,  77],\n",
       "         ...,\n",
       "         [ 42,  97,  96],\n",
       "         [ 50, 112,  81],\n",
       "         [120, 162, 188]],\n",
       "\n",
       "        [[118, 160, 189],\n",
       "         [ 48,  97,  87],\n",
       "         [ 43, 102,  80],\n",
       "         ...,\n",
       "         [ 41, 104, 100],\n",
       "         [ 43, 100,  85],\n",
       "         [116, 162, 189]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[116, 159, 187],\n",
       "         [ 43, 106,  84],\n",
       "         [ 37, 111,  90],\n",
       "         ...,\n",
       "         [ 46,  84,  65],\n",
       "         [ 49,  92,  67],\n",
       "         [115, 161, 190]],\n",
       "\n",
       "        [[115, 160, 188],\n",
       "         [186, 202, 198],\n",
       "         [159, 183, 178],\n",
       "         ...,\n",
       "         [ 21,  89,  73],\n",
       "         [ 22,  86,  76],\n",
       "         [120, 161, 192]],\n",
       "\n",
       "        [[114, 159, 189],\n",
       "         [116, 160, 196],\n",
       "         [119, 158, 196],\n",
       "         ...,\n",
       "         [122, 160, 195],\n",
       "         [117, 162, 191],\n",
       "         [115, 160, 186]]],\n",
       "\n",
       "\n",
       "       [[[240, 248, 238],\n",
       "         [241, 249, 239],\n",
       "         [242, 250, 240],\n",
       "         ...,\n",
       "         [247, 255, 245],\n",
       "         [247, 255, 245],\n",
       "         [247, 255, 245]],\n",
       "\n",
       "        [[241, 249, 239],\n",
       "         [240, 248, 238],\n",
       "         [241, 249, 239],\n",
       "         ...,\n",
       "         [247, 255, 245],\n",
       "         [247, 255, 245],\n",
       "         [247, 255, 245]],\n",
       "\n",
       "        [[240, 248, 238],\n",
       "         [240, 248, 238],\n",
       "         [241, 249, 239],\n",
       "         ...,\n",
       "         [247, 255, 245],\n",
       "         [246, 253, 246],\n",
       "         [247, 255, 245]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[242, 251, 241],\n",
       "         [243, 250, 244],\n",
       "         [243, 251, 241],\n",
       "         ...,\n",
       "         [ 15,  30,  23],\n",
       "         [  8,  27,  23],\n",
       "         [ 15,  34,  32]],\n",
       "\n",
       "        [[242, 250, 243],\n",
       "         [244, 252, 242],\n",
       "         [243, 251, 241],\n",
       "         ...,\n",
       "         [244, 253, 243],\n",
       "         [202, 238, 249],\n",
       "         [  3,  23,  24]],\n",
       "\n",
       "        [[242, 250, 240],\n",
       "         [244, 250, 245],\n",
       "         [244, 252, 242],\n",
       "         ...,\n",
       "         [244, 252, 242],\n",
       "         [240, 252, 243],\n",
       "         [242, 247, 244]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001.Black_footed_Albatross', '001.Black_footed_Albatross',\n",
       "       '001.Black_footed_Albatross', ..., '040.Olive_sided_Flycatcher',\n",
       "       '040.Olive_sided_Flycatcher', '040.Olive_sided_Flycatcher'],\n",
       "      dtype='<U28')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = os.listdir('Birds/test/')\n",
    "alphabet_directory_test='Birds/test/'\n",
    "datay = []\n",
    "datax=[]\n",
    "for character in characters:\n",
    "        images = os.listdir('Birds/test/' + character + '/')\n",
    "        for img in images:\n",
    "            image = cv2.resize(cv2.imread(alphabet_directory_test + character + '/' + img), (42,42))\n",
    "            #image = np.expand_dims(image, 0)\n",
    "            datax.append( image)\n",
    "            datay.append(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx=np.array(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 42, 42, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testy=np.array(datay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Grocery set, use original rotation 4 times as augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Grocery = os.listdir('Grocery/train/') #juice / milk /oatghurt / oat-milk / sour-cream\n",
    "datax = np.array([])\n",
    "def image_rotate(img, angle):\n",
    "    \"\"\"\n",
    "    Image rotation at certain angle. It is used for data augmentation \n",
    "    \"\"\"\n",
    "    rows,cols, _ = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2 ,rows/2),angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return np.expand_dims(dst, 0)\n",
    "\n",
    "def read_alphabets(alphabet_directory, directory):\n",
    "    \"\"\"\n",
    "    Reads all the characters from alphabet_directory and augment each image with 90, 180, 270 degrees of rotation.\n",
    "    \"\"\"\n",
    "    datax = None\n",
    "    datay = []\n",
    "    characters = os.listdir(alphabet_directory)\n",
    "    for character in characters:\n",
    "        images = os.listdir(alphabet_directory + character + '/')\n",
    "        for img in images:\n",
    "            image = cv2.resize(cv2.imread(alphabet_directory + character + '/' + img), (42,42))\n",
    "            image90 = image_rotate(image, 90)\n",
    "            image180 = image_rotate(image, 180)\n",
    "            image270 = image_rotate(image, 270)\n",
    "            image = np.expand_dims(image, 0)\n",
    "            if datax is None:\n",
    "                datax = np.vstack([image, image90, image180, image270])\n",
    "            else:\n",
    "                datax = np.vstack([datax, image, image90, image180, image270])\n",
    "            datay.append(directory + '_' + character + '_0')\n",
    "            datay.append(directory + '_' + character + '_90')\n",
    "            datay.append(directory + '_' + character + '_180')\n",
    "            datay.append(directory + '_' + character + '_270')\n",
    "    return datax, np.array(datay)\n",
    "\n",
    "def read_images(base_directory):\n",
    "    \"\"\"\n",
    "    Used multithreading for data reading to decrease the reading time drastically\n",
    "    \"\"\"\n",
    "    datax = None\n",
    "    datay = []\n",
    "    \n",
    "    results = [read_alphabets(base_directory + '/' + directory + '/', directory, ) for directory in os.listdir(base_directory)]\n",
    "  \n",
    "    for result in results:\n",
    "        if datax is None:\n",
    "            datax = result[0]\n",
    "            datay = result[1]\n",
    "        else:\n",
    "            datax = np.vstack([datax, result[0]])\n",
    "            datay = np.concatenate([datay, result[1]])\n",
    "    return datax, datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%time G_trainx, G_trainy = read_images('Grocery/train/Packages/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2168, 42, 42, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_trainx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Juice_Bravo-Apple-Juice_0', 'Juice_Bravo-Apple-Juice_90',\n",
       "       'Juice_Bravo-Apple-Juice_180', ...,\n",
       "       'Sour-Cream_Arla-Sour-Cream_90', 'Sour-Cream_Arla-Sour-Cream_180',\n",
       "       'Sour-Cream_Arla-Sour-Cream_270'], dtype='<U48')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 596 ms\n"
     ]
    }
   ],
   "source": [
    "%time G_testx, G_testy = read_images('Grocery/test/Packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1288, 42, 42, 3), (1288,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_testx.shape,G_testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sour-Milk_Arla-Sour-Milk_0', 'Sour-Milk_Arla-Sour-Milk_90',\n",
       "       'Sour-Milk_Arla-Sour-Milk_180', ...,\n",
       "       'Yoghurt_Yoggi-Vanilla-Yoghurt_90',\n",
       "       'Yoghurt_Yoggi-Vanilla-Yoghurt_180',\n",
       "       'Yoghurt_Yoggi-Vanilla-Yoghurt_270'], dtype='<U45')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_testy=np.hstack([testy, G_testy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['170.Mourning_Warbler', '170.Mourning_Warbler',\n",
       "       '170.Mourning_Warbler', ..., 'Yoghurt_Yoggi-Vanilla-Yoghurt_90',\n",
       "       'Yoghurt_Yoggi-Vanilla-Yoghurt_180',\n",
       "       'Yoghurt_Yoggi-Vanilla-Yoghurt_270'], dtype='<U45')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2122,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 64, 102,  92],\n",
       "         [ 37,  74,  65],\n",
       "         [ 57, 107,  95],\n",
       "         ...,\n",
       "         [ 15,  44,  29],\n",
       "         [ 19,  48,  33],\n",
       "         [ 27,  62,  46]],\n",
       "\n",
       "        [[ 44,  89,  83],\n",
       "         [ 49, 100,  83],\n",
       "         [ 57,  99,  90],\n",
       "         ...,\n",
       "         [ 16,  41,  31],\n",
       "         [ 17,  44,  34],\n",
       "         [ 73,  92,  69]],\n",
       "\n",
       "        [[ 81, 136, 127],\n",
       "         [ 37,  83,  73],\n",
       "         [ 57, 104,  96],\n",
       "         ...,\n",
       "         [ 11,  42,  27],\n",
       "         [ 14,  48,  34],\n",
       "         [ 56,  83,  65]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  8,  57,  47],\n",
       "         [ 19,  82,  71],\n",
       "         [ 40, 117, 103],\n",
       "         ...,\n",
       "         [ 12,  29,  26],\n",
       "         [ 19,  24,  24],\n",
       "         [  5,  10,   9]],\n",
       "\n",
       "        [[  8,  46,  34],\n",
       "         [ 18,  78,  65],\n",
       "         [ 36, 114, 101],\n",
       "         ...,\n",
       "         [  2,  44,  31],\n",
       "         [ 15,  39,  35],\n",
       "         [ 10,  16,  14]],\n",
       "\n",
       "        [[  3,  44,  30],\n",
       "         [ 19,  74,  62],\n",
       "         [ 65, 125, 119],\n",
       "         ...,\n",
       "         [111, 174, 182],\n",
       "         [ 65, 137, 125],\n",
       "         [ 18,  76,  61]]],\n",
       "\n",
       "\n",
       "       [[[ 17, 153, 201],\n",
       "         [  7, 129, 183],\n",
       "         [  2,  98, 161],\n",
       "         ...,\n",
       "         [250, 203, 169],\n",
       "         [247, 199, 165],\n",
       "         [248, 201, 163]],\n",
       "\n",
       "        [[ 25, 156, 200],\n",
       "         [ 13, 129, 180],\n",
       "         [  7, 102, 159],\n",
       "         ...,\n",
       "         [253, 201, 164],\n",
       "         [248, 201, 163],\n",
       "         [251, 199, 162]],\n",
       "\n",
       "        [[ 24, 155, 198],\n",
       "         [ 10, 121, 171],\n",
       "         [ 58, 121, 158],\n",
       "         ...,\n",
       "         [247, 202, 164],\n",
       "         [249, 202, 164],\n",
       "         [251, 199, 162]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 98, 101, 105],\n",
       "         [116, 110, 112],\n",
       "         [150, 148, 148],\n",
       "         ...,\n",
       "         [148, 114, 179],\n",
       "         [155, 128, 184],\n",
       "         [163, 134, 188]],\n",
       "\n",
       "        [[103,  97,  98],\n",
       "         [104, 102, 102],\n",
       "         [148, 146, 146],\n",
       "         ...,\n",
       "         [153, 118, 182],\n",
       "         [157, 131, 185],\n",
       "         [165, 145, 192]],\n",
       "\n",
       "        [[ 93,  90,  91],\n",
       "         [ 98,  96,  96],\n",
       "         [143, 141, 141],\n",
       "         ...,\n",
       "         [153, 119, 180],\n",
       "         [163, 141, 189],\n",
       "         [162, 145, 188]]],\n",
       "\n",
       "\n",
       "       [[[ 29,  41,  36],\n",
       "         [ 28,  33,  34],\n",
       "         [ 57,  63,  68],\n",
       "         ...,\n",
       "         [115, 193, 117],\n",
       "         [141, 205, 136],\n",
       "         [169, 210, 153]],\n",
       "\n",
       "        [[ 38,  62,  52],\n",
       "         [ 37,  42,  43],\n",
       "         [ 96, 125,  98],\n",
       "         ...,\n",
       "         [ 81, 184, 103],\n",
       "         [109, 197, 120],\n",
       "         [135, 206, 141]],\n",
       "\n",
       "        [[ 34,  87,  60],\n",
       "         [ 23,  31,  24],\n",
       "         [ 39,  38,  40],\n",
       "         ...,\n",
       "         [ 51, 176,  97],\n",
       "         [ 69, 186, 112],\n",
       "         [ 92, 191, 119]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[195, 224, 193],\n",
       "         [ 73,  86,  87],\n",
       "         [128, 139, 140],\n",
       "         ...,\n",
       "         [204, 213, 193],\n",
       "         [185, 205, 171],\n",
       "         [210, 216, 196]],\n",
       "\n",
       "        [[173, 216, 178],\n",
       "         [ 73,  88,  90],\n",
       "         [122, 134, 135],\n",
       "         ...,\n",
       "         [197, 211, 184],\n",
       "         [178, 198, 160],\n",
       "         [200, 213, 191]],\n",
       "\n",
       "        [[124, 196, 144],\n",
       "         [ 75,  88,  88],\n",
       "         [124, 136, 138],\n",
       "         ...,\n",
       "         [168, 201, 148],\n",
       "         [187, 205, 174],\n",
       "         [133, 206, 130]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[ 86,  94,  91],\n",
       "         [ 16,  31,  36],\n",
       "         [ 69,  89,  97],\n",
       "         ...,\n",
       "         [ 88, 107, 122],\n",
       "         [100, 119, 134],\n",
       "         [102, 120, 137]],\n",
       "\n",
       "        [[ 95,  93,  84],\n",
       "         [142, 152, 159],\n",
       "         [ 69,  84,  87],\n",
       "         ...,\n",
       "         [ 98, 116, 133],\n",
       "         [ 94, 112, 129],\n",
       "         [ 96, 114, 131]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[125, 118, 124],\n",
       "         [ 68,  65,  76],\n",
       "         [ 65,  72,  82],\n",
       "         ...,\n",
       "         [ 96, 117, 149],\n",
       "         [ 92, 114, 146],\n",
       "         [ 52,  77, 109]],\n",
       "\n",
       "        [[124, 117, 123],\n",
       "         [ 69,  65,  76],\n",
       "         [ 85,  87,  98],\n",
       "         ...,\n",
       "         [ 85, 106, 138],\n",
       "         [ 93, 113, 145],\n",
       "         [ 92, 110, 139]],\n",
       "\n",
       "        [[ 88,  85,  90],\n",
       "         [ 77,  69,  80],\n",
       "         [ 69,  71,  81],\n",
       "         ...,\n",
       "         [ 80, 101, 132],\n",
       "         [ 84, 105, 136],\n",
       "         [ 93, 112, 138]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [102, 120, 137],\n",
       "         [ 96, 114, 131],\n",
       "         ...,\n",
       "         [ 52,  77, 109],\n",
       "         [ 92, 110, 139],\n",
       "         [ 93, 112, 138]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [100, 119, 134],\n",
       "         [ 94, 112, 129],\n",
       "         ...,\n",
       "         [ 92, 114, 146],\n",
       "         [ 93, 113, 145],\n",
       "         [ 84, 105, 136]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 75,  93, 106],\n",
       "         [ 15,  33,  34],\n",
       "         ...,\n",
       "         [ 34,  56,  74],\n",
       "         [ 43,  58,  77],\n",
       "         [ 46,  64,  80]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 69,  89,  97],\n",
       "         [ 69,  84,  87],\n",
       "         ...,\n",
       "         [ 65,  72,  82],\n",
       "         [ 85,  87,  98],\n",
       "         [ 69,  71,  81]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 16,  31,  36],\n",
       "         [142, 152, 159],\n",
       "         ...,\n",
       "         [ 68,  65,  76],\n",
       "         [ 69,  65,  76],\n",
       "         [ 77,  69,  80]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0],\n",
       "         [ 84, 107, 132],\n",
       "         [ 80, 102, 132],\n",
       "         ...,\n",
       "         [ 51,  69,  85],\n",
       "         [ 75,  76,  86],\n",
       "         [ 76,  73,  84]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 93, 112, 138],\n",
       "         [ 84, 105, 136],\n",
       "         ...,\n",
       "         [ 46,  64,  80],\n",
       "         [ 69,  71,  81],\n",
       "         [ 77,  69,  80]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 92, 110, 139],\n",
       "         [ 93, 113, 145],\n",
       "         ...,\n",
       "         [ 43,  58,  77],\n",
       "         [ 85,  87,  98],\n",
       "         [ 69,  65,  76]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 98, 116, 133],\n",
       "         [ 99, 117, 134],\n",
       "         ...,\n",
       "         [ 89,  97,  97],\n",
       "         [ 81,  92,  96],\n",
       "         [137, 146, 154]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [ 96, 114, 131],\n",
       "         [ 94, 112, 129],\n",
       "         ...,\n",
       "         [ 15,  33,  34],\n",
       "         [ 69,  84,  87],\n",
       "         [142, 152, 159]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [102, 120, 137],\n",
       "         [100, 119, 134],\n",
       "         ...,\n",
       "         [ 75,  93, 106],\n",
       "         [ 69,  89,  97],\n",
       "         [ 16,  31,  36]]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_testx=np.vstack([testx, G_testx])\n",
    "Full_testx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2122, 42, 42, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_testx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # stack up: birds train+Grocery train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_trainx=np.vstack([trainx, G_trainx])\n",
    "Full_trainy=np.hstack([trainy, G_trainy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4458, 42, 42, 3), (4458, 42, 42, 3))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_trainx.shape, Full_trainx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classes for train , class[1-100], test classes [170-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "from time import sleep\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_trainx = torch.from_numpy(Full_trainx).float()\n",
    "Full_testx = torch.from_numpy(Full_testx).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid CUDA out of memory error\n",
    "    #Send the batches to CUDA iteratively, and make small batch sizes.\n",
    "    #Don't send all your data to CUDA at once in the beginning. \n",
    "\"\"\"\n",
    "if use_gpu:\n",
    "    trainx = trainx.cuda()\n",
    "    testx = testx.cuda()#.half() #\n",
    "trainx.size()\"\"\" #, testx.size()\n",
    "# use dtypes that use less memory. For instance, torch.float16 or torch.half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_trainx = Full_trainx.permute(0,3,1,2)\n",
    "Full_testx = Full_testx.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image2Vector CNN (we can use other pre-trained model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Image2Vector CNN which takes image of dimension (42x42x3) and return column vector length 224\n",
    "    \"\"\"\n",
    "    def sub_block(self, in_channels, out_channels=64, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.MaxPool2d(kernel_size=2)\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.convnet1 = self.sub_block(3)\n",
    "        self.convnet2 = self.sub_block(64)\n",
    "        self.convnet3 = self.sub_block(64)\n",
    "        self.convnet4 = self.sub_block(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convnet1(x)\n",
    "        x = self.convnet2(x)\n",
    "        x = self.convnet3(x)\n",
    "        x = self.convnet4(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrototypicalNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNet(nn.Module):\n",
    "    def __init__(self, use_gpu=False):\n",
    "        super(PrototypicalNet, self).__init__()       \n",
    "        self.f = Net()\n",
    "        #self.f =model\n",
    "        self.gpu = use_gpu\n",
    "        if self.gpu:\n",
    "            self.f = self.f.cuda()\n",
    "    \n",
    "    def forward(self, datax, datay, Ns,Nc, Nq, total_classes):\n",
    "        \"\"\"\n",
    "        Implementation of one episode in Prototypical Net\n",
    "        datax: Training images\n",
    "        datay: Corresponding labels of datax\n",
    "        Nc: Number  of classes per episode\n",
    "        Ns: Number of support data per class\n",
    "        Nq:  Number of query data per class\n",
    "        total_classes: Total classes in training set\n",
    "        \"\"\"\n",
    "        k = total_classes.shape[0]\n",
    "        K = np.random.choice(total_classes, Nc, replace=False)\n",
    "        Query_x = torch.Tensor()\n",
    "        if(self.gpu):\n",
    "            Query_x = Query_x.cuda()\n",
    "        Query_y = []\n",
    "        Query_y_count = []\n",
    "        centroid_per_class  = {}\n",
    "        class_label = {}\n",
    "        label_encoding = 0\n",
    "        for cls in K:\n",
    "            S_cls, Q_cls = self.random_sample_cls(datax, datay, Ns, Nq, cls)\n",
    "            centroid_per_class[cls] = self.get_centroid(S_cls, Ns)\n",
    "            class_label[cls] = label_encoding\n",
    "            label_encoding += 1\n",
    "            Query_x = torch.cat((Query_x, Q_cls), 0) # Joining all the query set together\n",
    "            Query_y += [cls]\n",
    "            Query_y_count += [Q_cls.shape[0]]\n",
    "        Query_y, Query_y_labels = self.get_query_y(Query_y, Query_y_count, class_label)\n",
    "        Query_x = self.get_query_x(Query_x, centroid_per_class, Query_y_labels)\n",
    "        return Query_x, Query_y\n",
    "    \n",
    "    def random_sample_cls(self, datax, datay, Ns, Nq, cls):\n",
    "        \"\"\"\n",
    "        Randomly samples Ns examples as support set and Nq as Query set\n",
    "        \"\"\"\n",
    "        data = datax[(datay == cls).nonzero()]\n",
    "        perm = torch.randperm(data.shape[0])\n",
    "        idx = perm[:Ns]\n",
    "        S_cls = data[idx]\n",
    "        idx = perm[Ns : Ns+Nq]\n",
    "        Q_cls = data[idx]\n",
    "        if self.gpu:\n",
    "            S_cls = S_cls.cuda() \n",
    "            Q_cls = Q_cls.cuda() \n",
    "        return S_cls, Q_cls\n",
    "    \n",
    "    def get_centroid(self, S_cls, Nc):\n",
    "        \"\"\"\n",
    "        Returns a centroid vector of support set for a class\n",
    "        \"\"\"\n",
    "        return torch.sum(self.f(S_cls), 0).unsqueeze(1).transpose(0,1) / Nc\n",
    "    \n",
    "    def get_query_y(self, Qy, Qyc, class_label):\n",
    "        \"\"\"\n",
    "        Returns labeled representation of classes of Query set and a list of labels.\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        m = len(Qy)\n",
    "        for i in range(m):\n",
    "            labels += [Qy[i]] * Qyc[i]\n",
    "        labels = np.array(labels).reshape(len(labels), 1)\n",
    "        label_encoder = LabelEncoder()\n",
    "        Query_y = torch.Tensor(label_encoder.fit_transform(labels).astype(int)).long()\n",
    "        if self.gpu:\n",
    "            Query_y = Query_y.cuda()\n",
    "        Query_y_labels = np.unique(labels)\n",
    "        return Query_y, Query_y_labels\n",
    "    \n",
    "    def get_centroid_matrix(self, centroid_per_class, Query_y_labels):\n",
    "        \"\"\"\n",
    "        Returns the centroid matrix where each column is a centroid of a class.\n",
    "        \"\"\"\n",
    "        centroid_matrix = torch.Tensor()\n",
    "        if(self.gpu):\n",
    "            centroid_matrix = centroid_matrix.cuda()\n",
    "        for label in Query_y_labels:\n",
    "            centroid_matrix = torch.cat((centroid_matrix, centroid_per_class[label]))\n",
    "        if self.gpu:\n",
    "            centroid_matrix = centroid_matrix.cuda()\n",
    "        return centroid_matrix\n",
    "    \n",
    "    def get_query_x(self, Query_x, centroid_per_class, Query_y_labels):\n",
    "        \"\"\"\n",
    "        Returns distance matrix from each Query image to each centroid.\n",
    "        \"\"\"\n",
    "        centroid_matrix = self.get_centroid_matrix(centroid_per_class, Query_y_labels)\n",
    "        Query_x = self.f(Query_x)\n",
    "        m = Query_x.size(0)\n",
    "        n = centroid_matrix.size(0)\n",
    "        # The below expressions expand both the matrices such that they become compatible to each other in order to caclulate L2 distance.\n",
    "        centroid_matrix = centroid_matrix.expand(m, centroid_matrix.size(0), centroid_matrix.size(1)) # Expanding centroid matrix to \"m\".\n",
    "        Query_matrix = Query_x.expand(n, Query_x.size(0), Query_x.size(1)).transpose(0,1) # Expanding Query matrix \"n\" times\n",
    "        Qx = torch.pairwise_distance(centroid_matrix.transpose(1,2), Query_matrix.transpose(1,2))\n",
    "        return Qx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protonet = PrototypicalNet(use_gpu=use_gpu)\n",
    "optimizer = optim.SGD(protonet.parameters(), lr = 0.01, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(datax, datay, Ns,Nc, Nq):\n",
    "    optimizer.zero_grad()\n",
    "    Qx, Qy= protonet(datax, datay, Ns, Nc, Nq, np.unique(datay))\n",
    "    pred = torch.log_softmax(Qx, dim=-1)\n",
    "    loss = F.nll_loss(pred, Qy)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = torch.mean((torch.argmax(pred, 1) == Qy).float())\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episode = 20000\n",
    "frame_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\april\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 09:46:33.563066 Frame Number: 1 Frame Loss:  1.88402294921875 Frame Accuracy: 31.610336303710938\n",
      "2020-05-03 09:48:45.728083 Frame Number: 2 Frame Loss:  1.10334912109375 Frame Accuracy: 58.553717041015624\n",
      "2020-05-03 09:50:58.021913 Frame Number: 3 Frame Loss:  0.8382232666015625 Frame Accuracy: 68.29754028320312\n",
      "2020-05-03 09:53:10.208979 Frame Number: 4 Frame Loss:  0.7029210815429687 Frame Accuracy: 73.492431640625\n",
      "2020-05-03 09:55:22.447417 Frame Number: 5 Frame Loss:  0.6033626708984375 Frame Accuracy: 77.1947998046875\n",
      "2020-05-03 09:57:33.018901 Frame Number: 6 Frame Loss:  0.5365086669921875 Frame Accuracy: 79.66160888671875\n",
      "2020-05-03 09:59:43.615490 Frame Number: 7 Frame Loss:  0.4714530944824219 Frame Accuracy: 82.08367309570312\n",
      "2020-05-03 10:01:54.170033 Frame Number: 8 Frame Loss:  0.4051081848144531 Frame Accuracy: 84.55684814453124\n",
      "2020-05-03 10:04:04.757168 Frame Number: 9 Frame Loss:  0.37212741088867185 Frame Accuracy: 85.66818237304688\n",
      "2020-05-03 10:06:15.512990 Frame Number: 10 Frame Loss:  0.377530029296875 Frame Accuracy: 85.7920166015625\n",
      "2020-05-03 10:08:26.247112 Frame Number: 11 Frame Loss:  0.3154352722167969 Frame Accuracy: 87.97319946289062\n",
      "2020-05-03 10:10:37.842962 Frame Number: 12 Frame Loss:  0.27940142822265623 Frame Accuracy: 89.22154541015625\n",
      "2020-05-03 10:12:50.270817 Frame Number: 13 Frame Loss:  0.26813540649414064 Frame Accuracy: 89.89004516601562\n",
      "2020-05-03 10:15:01.791132 Frame Number: 14 Frame Loss:  0.243968017578125 Frame Accuracy: 90.69705200195312\n",
      "2020-05-03 10:17:13.261570 Frame Number: 15 Frame Loss:  0.22346617126464843 Frame Accuracy: 91.54807739257812\n",
      "2020-05-03 10:19:24.846320 Frame Number: 16 Frame Loss:  0.21150120544433593 Frame Accuracy: 91.98250122070313\n",
      "2020-05-03 10:21:36.675992 Frame Number: 17 Frame Loss:  0.1899997863769531 Frame Accuracy: 92.86135864257812\n",
      "2020-05-03 10:23:48.353246 Frame Number: 18 Frame Loss:  0.17832568359375 Frame Accuracy: 93.30278930664062\n",
      "2020-05-03 10:26:00.239629 Frame Number: 19 Frame Loss:  0.1703314971923828 Frame Accuracy: 93.59437255859375\n",
      "2020-05-03 10:28:12.029367 Frame Number: 20 Frame Loss:  0.16977690124511718 Frame Accuracy: 93.62772827148437\n"
     ]
    }
   ],
   "source": [
    "frame_loss = 0\n",
    "frame_acc = 0\n",
    "for i in range(num_episode):\n",
    "    #To avoid CUDA out of memory error\n",
    "    #Send the batches to CUDA iteratively, and make small batch sizes.\n",
    "    #Don't send all your data to CUDA at once in the beginning. Rather, do it as follows: \n",
    "    if use_gpu:\n",
    "        Full_trainx = Full_trainx.cuda() \n",
    "     \n",
    "    loss, acc = train_step(Full_trainx, Full_trainy, 5, 20, 15) # is Nc: Number  of classes per episode, can by tuned later\n",
    "    frame_loss += loss.data\n",
    "    frame_acc += acc.data\n",
    "    if( (i+1) % frame_size == 0):\n",
    "        print(datetime.datetime.now(),\"Frame Number:\", ((i+1) // frame_size), 'Frame Loss: ', frame_loss.data.cpu().numpy().tolist()/ frame_size, 'Frame Accuracy:', (frame_acc.data.cpu().numpy().tolist() * 100) / frame_size)\n",
    "        frame_loss = 0\n",
    "        frame_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(datax, datay, Ns,Nc, Nq):\n",
    "    Qx, Qy= protonet(datax, datay, Ns, Nc, Nq, np.unique(datay))\n",
    "    pred = torch.log_softmax(Qx, dim=-1)\n",
    "    loss = F.nll_loss(pred, Qy)\n",
    "    acc = torch.mean((torch.argmax(pred, 1) == Qy).float())\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss:  1.0831509765625 Avg Accuracy: 71.2436767578125\n"
     ]
    }
   ],
   "source": [
    "num_test_episode = 5000\n",
    "avg_loss = 0\n",
    "avg_acc = 0\n",
    "for _ in range(num_test_episode):\n",
    "    if use_gpu:\n",
    "        Full_testx = Full_testx.cuda()\n",
    "    loss, acc = test_step(Full_testx, Full_testy, 5, 5, 15)\n",
    "    avg_loss += loss.data\n",
    "    avg_acc += acc.data\n",
    "print('Avg Loss: ', avg_loss.data.cpu().numpy().tolist() / num_test_episode , 'Avg Accuracy:', (avg_acc.data.cpu().numpy().tolist() * 100) / num_test_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
